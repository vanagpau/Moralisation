---
title: "Pilot analysis"
author: "28819459"
date: "01/05/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries and working directory
```{r, results='hide', warning=FALSE, message = FALSE}

library(psych)
library(ggridges)
library(kableExtra)
library(mgsub)
library(rstatix)
library(psych)
library(pwr)
library(tidyverse)

#Set working directory
setwd("E:/R stuff/Moralisation") #for home PC
#setwd("/home/vanagpau/R/Moralisation") #for laptop

```

## Data import and wrangling
```{r, warning=FALSE, message = FALSE}

setwd("C:/Users/Ben 10/Documents/Paul COG NEURO MSc/Empirical project/Pilot actual DATA")

# Read in data frame 1
df1 <- read_csv("data_exp_44331-v24_questionnaire-j12y.csv")

# DATAFRAME 1

#Convert event indices to numeric
df1$Event.Index <- as.numeric(df1$`Event Index`)

# Create data-frame for post task questionnaire (j12y)
df1 <- df1 %>% filter(`Event Index` > 1 & `Event Index` < 9 & `Participant Status` == "complete") %>%
  select(c(`Event Index`, `Participant Private ID`, `Question Key`, `Response`))

# Convert variables to factors
df1$`Question Key` <- gsub("emotion ranking-", "Emotion Rank ", df1$`Question Key`)
df1$`Question Key` <- as.factor(df1$`Question Key`)
df1$Response <- as.factor(df1$Response)

# DATAFRAME 2

# Read in data frame 2
df2 <- read_csv("data_exp_44331-v24_task-4xn8.csv")

# Set up variable types and replace with meaningful/correct names
df2$Response <- as.numeric(df2$Response)
df2$`Spreadsheet Row` <- as.character(df2$`Spreadsheet Row`)
df2$`Spreadsheet Row` <- mgsub(df2$`Spreadsheet Row`, c("1","2","3","4"), c("Meat", "Self-driving cars", "Plastic", "E-waste"))
df2$`Spreadsheet Row` <- as.factor(df2$`Spreadsheet Row`)
df2$`Screen Name` <- gsub(" questionnaire", "", df2$`Screen Name`)
colnames(df2)[colnames(df2)=="Screen Name"] <- "Question"
df2$Question <- mgsub(df2$Question, "Familiarisation", "Familiarity")
df2$Question <- as.factor(df2$Question)
df2$`Zone Name` <- mgsub(df2$`Zone Name`, c("Zone4","Zone6","Zone8","Zone10"), c("core_belief", "right_wrong", "moral_issue", "just_know"))
colnames(df2)[colnames(df2)=="Participant Private ID"] <- "PID"

# Create data-frame for video moralisation task (4xn8)
df2 <- df2 %>% 
  filter(`Participant Status` == "complete" & is.na(Response) == FALSE ) %>%
  select(c(`Event Index`, `PID`, `Spreadsheet Row`, Question, `Zone Name`, Response))

# Rename `Spreadsheet Row` column as Issue
names(df2)[3] <- "Issue"

# Order pre/post factors for graphing
df2$Question <- ordered(df2$Question, levels = c("Familiarity", "Pre-stim", "Post-stim"))

```

## Data analysis
```{r, warning=FALSE, message = FALSE}
# Extract comments for most emotional video PER PARTICIPANT
tibble(df1$Response[df1$`Event Index` == 4], df1$Response[df1$`Event Index` == 8]) %>%
  kbl() %>% kable_styling(bootstrap_options = "striped")

# Comments overall
tibble(df1$Response[df1$`Event Index` == 2]) %>%
  kbl() %>% kable_styling(bootstrap_options = "striped")

# Comments on understanding
tibble(df1$Response[df1$`Event Index` == 3]) %>%
  kbl() %>% kable_styling(bootstrap_options = "striped")

# Plot: Ridge histogram of emotion ranking
df1 %>% filter(`Event Index` > 3 & `Event Index` < 8) %>% 
  ggplot( aes(x=`Question Key`,y=Response,  height = stat(count), fill = Response)) +
    geom_density_ridges(alpha=0.6, stat="binline", bins=4, scale = 0.95) +
    theme(legend.position="none",
      strip.text.x = element_text(size = 8)
       )  + theme(axis.text.x = element_text(angle = 30)) +
    xlab("") +
    ylab("")


# Calculate Cronbach's Alpha for pre and post moralisation scores

for (i in c(2, 6, 10, 14, 18, 22, 26, 30)) {
print(df2 %>% filter(`Zone Name` != "slider") %>% pivot_wider(id_cols = PID, names_from = c(Issue, Question, `Zone Name`), values_from = Response) %>% select(.,i:(i+3)) %>% psych::alpha())
}

# Create table of mean composite values for each issue
df2 %>% group_by(Issue, Question) %>%
  # group by issue and question (familiar/pre/post)
  summarise(Mean = mean(Response), SE = signif(sd(Response) / sqrt(length(Response)),2)) %>%
  # calculate mean and standard error
  kbl() %>% kable_styling() # make table

# Check that dependent variable is normally distributed

# Visual check - density plot Pre-stimulus
df2 %>% filter(Question == "Pre-stim") %>%
  group_by(Issue, PID) %>% 
  mutate(Mean = mean(Response)) %>%
  select(PID, Issue, Mean) %>%
  unique() %>%
ggplot(aes(x = Mean)) +  stat_density(aes(group = Issue, color = Issue),position="identity",geom="line", size = 2) + facet_wrap(~Issue) + theme_classic() + ggtitle("Pre")

# Visual check - density plot Post-stimulus
df2 %>% filter(Question == "Post-stim") %>%
  group_by(Issue, PID) %>% 
  mutate(Mean = mean(Response)) %>%
  select(PID, Issue, Mean) %>%
  unique() %>%
ggplot(aes(x = Mean)) +  stat_density(aes(group = Issue, color = Issue),position="identity",geom="line", size = 2) + facet_wrap(~Issue) + theme_classic()

# QQ plots
# Pre-stimulus
df2 %>% filter(Question == "Pre-stim") %>%
  group_by(Issue, PID) %>% 
  mutate(Mean = mean(Response)) %>%
  ungroup () %>%
  select(Issue, Mean)  %>%
  unique() %>% ggplot(aes(sample = Mean)) + geom_qq(shape = 1) +
  geom_qq_line(colour = "red") + facet_wrap(~Issue)

# Post-stimulus
df2 %>% filter(Question == "Post-stim") %>%
  group_by(Issue, PID) %>% 
  mutate(Mean = mean(Response)) %>%
  ungroup () %>%
  select(Issue, Mean)  %>%
  unique() %>% ggplot(aes(sample = Mean)) + geom_qq(shape = 1) +
  geom_qq_line(colour = "red") + facet_wrap(~Issue)

# Shapiro-Wilk tests
df2 %>% filter(is.na(Question) == FALSE) %>%
  group_by(Question, Issue, PID) %>% 
  mutate(Mean = mean(Response)) %>%
  ungroup() %>%
  select(PID, Question, Issue, Mean) %>%
  unique() %>%
  pivot_wider(names_from = c(Question, Issue), values_from = Mean) %>%
  lapply(., shapiro_test) 



# Plot
df2 %>% ggplot(aes(x=Question, y=Response, fill=Issue)) + facet_wrap(df2$Issue) + geom_boxplot() + ylab("Moral Score") + xlab("") + geom_jitter(width=0.1,alpha=0.3)

# Calculate mean familiarity scores
df2 %>% group_by(Question, Issue) %>% summarise (Mean = mean(Response)) %>% unique() 


# paired t tests for moralisation score before and after

df2 %>% filter(Issue == "Self-driving cars", `Zone Name` != "slider") %>%
  # select cars issue and ignore slider(familiarity) questions
  group_by(Question, PID) %>% 
  # group by question (pre/post) and participant ID
  mutate(m = mean(Response)) %>%
  # create variable m which is mean of questionnaire items in pre and post for each participant 
  select(Question, m) %>%
  # select only columns required (not strictly necessary but neater)
  unique() %>%
  # collapse duplicate rows
  t.test(m ~ Question, data = ., paired = TRUE)
  # perform paired t-test of how mean (m) depends on Questions (pre / post)

# repeat t-test for each issue
df2 %>% filter(Issue == "Meat", `Zone Name` != "slider") %>% group_by(Question, PID) %>% mutate(m = mean(Response)) %>% select(Question, m) %>% unique() %>% t.test(m ~ Question, data = ., paired = TRUE)
df2 %>% filter(Issue == "Plastic", `Zone Name` != "slider") %>% group_by(Question, PID) %>% mutate(m = mean(Response)) %>% select(Question, m) %>% unique() %>% t.test(m ~ Question, data = ., paired = TRUE)
df2 %>% filter(Issue == "E-waste", `Zone Name` != "slider") %>% group_by(Question, PID) %>% mutate(m = mean(Response)) %>% select(Question, m) %>% unique() %>% t.test(m ~ Question, data = ., paired = TRUE)

# Effect sizes
# Convert Question variable into character to enable use of cohen's d function
df2$Question <- as.character(df2$Question)

# create vector of issues for looping
issues <- c("Plastic", "E-waste", "Meat", "Self-driving cars")

# create function to calculate Cohen's d and put into table
cohen_fn = function(var) {
  data.frame( df2 %>%
                # create a data frame to produce a tablular output at the end
                filter(Issue == var, `Zone Name` != "slider") %>%
                # select issue and ignore slider(familiarity) questions
                group_by(Question, PID) %>%
                # group by question (pre/post) and participant ID
                mutate(m = mean(Response)) %>%
                # create variable m which is mean of questionnaire items in pre and post for each participant 
                select(Question, m) %>%
                # select only columns required)
                unique() %>%
                # collapse duplicate rows
                ungroup() %>%
                # remove grouping (otherwise cohens_d won't recognise columns)
                rstatix::cohens_d(., m ~ Question, paired = TRUE),
                # run cohens d
                Issue = var)
                # add name of variable to dataframe for clarity
}

# loop through each issue and produce tables
lapply(issues, cohen_fn)

# visual check for occurence of default ordering = how many times does "4" appear in following table = 2

df1 %>% filter(`Event Index` >3 & `Event Index` < 8) %>%
  # select only emotion rank q's
  filter(`Question Key` == "Emotion Rank 1" & Response == "Meat" | `Question Key` == "Emotion Rank 2" & Response == "Plastics" | `Question Key` == "Emotion Rank 3" & Response == "E-waste" | `Question Key` == "Emotion Rank 4" & Response == "Self-driving cars") %>%
  # select reponses corresponding to default order
  select(`Participant Private ID`) %>%
  # select participant ID variable only
  table()
# create table of number of times that participant appears in table, if = 4 then this exactly matches the default ordering


```













