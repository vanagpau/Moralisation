---
title: "Moralisation_MAIN"
author: "Paul V"
date: "10/06/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries
```{r, message=FALSE, warning=FALSE}

library(kableExtra)
library(psych)
library(car)
library(RColorBrewer)
library(lme4)
library(lattice)
library(faux)
library(simr)
library(tidyverse)


```


## Import data
```{r, message = FALSE, warning=FALSE, message=FALSE}

#clear workspace
rm(list = ls())

#laptop working directory
#setwd("/home/vanagpau/R/Moralisation/MAIN actual data") 

#desktop working directory
setwd("C:/Users/paulv/Documents/Paul COG NEURO MSc/Empirical project/MAIN actual data") 

# extract 4 character identifier for each questionnaire node
nam <- str_sub(list.files(pattern = "questionnaire"), -8, -5)

# combine all matching nodes
for (i in seq(1:length(nam))) {
  #read in each file, remove additional event as per text and combine all common questionnaire nodes
  df_temp <- list.files(pattern = nam[i]) %>% lapply(read_csv, na = c("Unexpectedly long close out at end of task!", "NA")) %>% bind_rows()
    df_temp <- df_temp %>% filter(`Event Index` != "END OF FILE") %>%
    filter(`Question Key` != "END QUESTIONNAIRE" &  `Question Key` != "BEGIN QUESTIONNAIRE",
           !grepl("quantised", `Question Key`) ) %>%
  select(`Participant Private ID`, `Question Key`, Response, `Tree Node Key`)# remove all END OF FILE lines
    colnames(df_temp)[colnames(df_temp)=="Participant Private ID"] <- "PID" #shorten col name to PID
    assign(paste0("n_",nam[i]), df_temp) #assign df to the name of the dataframe created above
}

#remove unnecessary dfs from environment (consent, debrief nodes, explainer, survey code pages etc)
rm(n_1dbi,n_o3u2, n_q986, n_1dbi, n_8941, n_gbx3)

#remove df_temp from workspace to prevent double counting
rm(df_temp)

#create list of remaining dataframes (as strings)
dflist <- Filter(function(x) is.data.frame(get(x)), ls())

#INCOMPLETE CODE
#create list of remaining dataframe (as objects)
#lapply(ls(pattern="n_"), function(x) get(x))
#save to csv for quick recall in subsequent chunk
#lapply(dflist, write_csv, file = paste0(dflist,".csv"))

```
## Data wrangle
```{r}


# replace categorical answers with numeric
n_4kh5$Response <- str_replace_all(n_4kh5$Response, c(
    "Not at all opposed" = "1", "Slightly opposed" = "2", "Somewhat opposed" = "3", "Strongly opposed" = "4")) %>%
  as.numeric()
n_k47v$Response <- str_replace_all(n_k47v$Response, c(
    "Not at all opposed" = "1", "Slightly opposed" = "2", "Somewhat opposed" = "3", "Strongly opposed" = "4")) %>%
  as.numeric()
n_sjbg$Response <- str_replace_all(n_sjbg$Response, c(
    "Not at all opposed" = "1", "Slightly opposed" = "2", "Somewhat opposed" = "3", "Strongly opposed" = "4")) %>%
  as.numeric()
n_wxzl$Response <- str_replace_all(n_wxzl$Response, c(
    "Not at all opposed" = "1", "Slightly opposed" = "2", "Somewhat opposed" = "3", "Strongly opposed" = "4")) %>%
  as.numeric()



# Reverse score item MIS4
n_ubog[n_ubog$`Question Key` == "MIS4",'Response'] <- n_ubog %>% filter(`Question Key`== "MIS4") %>% select(Response) %>% transmute(Response = 6 - Response)

# Add session no. info to the dataframes
n_4kh5$session <- 2
n_5hpk$session <- 3
n_9opr$session <- 2
n_auod$session <- 1
n_daab$session <- 2
n_fhoy$session <- 1
n_hhto$session <- 1
n_k47v$session <- 4
n_l8iw$session <- 4
n_lpz3$session <- 3
n_luva$session <- 3
n_okdo$session <- 1
n_p34a$session <- 1
n_sjbg$session <- 1
n_t7dh$session <- 1
n_txy2$session <- 2
n_ubog$session <- 1
n_vacc$session <- 3
n_wkz6$session <- 4
n_wxzl$session <- 3
n_xdo3$session <- 4
n_xuky$session <- 4
n_zd7j$session <- 2
n_zm3i$session <- 4

## Calculate mean scores for variables within individual dataframes (one variable / dataframe)

# create list of variable names to search for
var_names <- c("cog", "att", "pig", "hed", "HPRS", "moral", "diss", "emo", "emo_obj", "behav", "MIS")

# Cronbach alpha to check reliability of scales by session

# Create data frame where each column is a test/questionnaire item, each row is a person
df_all <- bind_rows(Filter(function(x) is(x, "data.frame"), mget(ls())))
df_all <- df_all %>% group_by(`PID`) %>% pivot_wider(id_cols = PID, names_from = c(`Question Key`, session), values_from = Response) %>% ungroup () 

# list of variables at all 4 time points
var_names4 <- c("cog", "att", "pig", "hed", "moral", "diss", "emo", "emo_obj")

# Run Cronbach alpha on each questionnaire - detected using regex string matching

# HASHED OUT FOR SPEED

# # Moral cognition 1
psych::alpha(df_all[,str_detect(colnames(df_all), "cog.*?1$")])
# # Moral cognition 2
# psych::alpha(df_all[,str_detect(colnames(df_all), "cog.*?2$")])
# # Moral cognition 3
# psych::alpha(df_all[,str_detect(colnames(df_all), "cog.*?3$")])
# # Moral cognition 4
# psych::alpha(df_all[,str_detect(colnames(df_all), "cog.*?4$")])
# # Attitude 1
# psych::alpha(df_all[,str_detect(colnames(df_all), "att.*?1$")])
# # Attitude 2
# psych::alpha(df_all[,str_detect(colnames(df_all), "att.*?2$")])
# # Attitude 3
# psych::alpha(df_all[,str_detect(colnames(df_all), "att.*?3$")])
# # Attitude 4
# psych::alpha(df_all[,str_detect(colnames(df_all), "att.*?4$")])
# # Moral piggybacking 1
# psych::alpha(df_all[,str_detect(colnames(df_all), "pig.*?1$")])
# # Moral piggybacking 2
# psych::alpha(df_all[,str_detect(colnames(df_all), "pig.*?2$")])
# # Moral piggybacking 3
# psych::alpha(df_all[,str_detect(colnames(df_all), "pig.*?3$")])
# # Moral piggybacking 4
# psych::alpha(df_all[,str_detect(colnames(df_all), "pig.*?4$")])
# # Hedonic motivation 1
# psych::alpha(df_all[,str_detect(colnames(df_all), "hed.*?1$")])
# # Hedonic motivation 2
# psych::alpha(df_all[,str_detect(colnames(df_all), "hed.*?2$")])
# # Hedonic motivation 3
# psych::alpha(df_all[,str_detect(colnames(df_all), "hed.*?3$")])
# # Hedonic motivation 4
# psych::alpha(df_all[,str_detect(colnames(df_all), "hed.*?4$")])
# # Moralisation 1
# psych::alpha(df_all[,str_detect(colnames(df_all), "moral.*?1$")])
# # Moralisation 2
# psych::alpha(df_all[,str_detect(colnames(df_all), "moral.*?2$")])
# # Moralisation 3
# psych::alpha(df_all[,str_detect(colnames(df_all), "moral.*?3$")])
# # Moralisation 4
# psych::alpha(df_all[,str_detect(colnames(df_all), "moral.*?4$")])
# # Dissonance Reduction 1
# psych::alpha(df_all[,str_detect(colnames(df_all), "diss.*?1$")])
# # Dissonance Reduction 2
# psych::alpha(df_all[,str_detect(colnames(df_all), "diss.*?2$")])
# # Dissonance Reduction 3
# psych::alpha(df_all[,str_detect(colnames(df_all), "diss.*?3$")])
# # Dissonance Reduction 4
# psych::alpha(df_all[,str_detect(colnames(df_all), "diss.*?4$")])
# # Moral emotions 1
# psych::alpha(df_all[,str_detect(colnames(df_all), "emo.*?1$")])
# # Moral emotions 2
# psych::alpha(df_all[,str_detect(colnames(df_all), "emo.*?2$")])
# # Moral emotions 3
# psych::alpha(df_all[,str_detect(colnames(df_all), "emo.*?3$")])
# # Moral emotions 4
psych::alpha(df_all[,str_detect(colnames(df_all), "emo.*?4$")])
# # Moral emotions (objects) 1
# psych::alpha(df_all[,str_detect(colnames(df_all), "emo_obj.*?1$")])
# # Moral emotions (objects) 2
# psych::alpha(df_all[,str_detect(colnames(df_all), "emo_obj.*?2$")])
# # Moral emotions (objects) 3
# psych::alpha(df_all[,str_detect(colnames(df_all), "emo_obj.*?3$")])
# # Moral emotions (objects) 4
# psych::alpha(df_all[,str_detect(colnames(df_all), "emo_obj.*?4$")])
# 
# # HPRS
psych::alpha(df_all[,str_detect(colnames(df_all), "HPRS")])
# # MIS
psych::alpha(df_all[,str_detect(colnames(df_all), "MIS")])
# 
# # Behavioural intentions 1
psych::alpha(df_all[,str_detect(colnames(df_all), "behav.*?1$")])
# # Behavioural intentions 2
psych::alpha(df_all[,str_detect(colnames(df_all), "behav.*?4$")])



# Create function to calculate variable scores
fn_var <- function(d, s1) {
 nam <- paste0(s1, get(d)[1,5]) #create dataframe name from input dataframe and variable string
 #filter and mutate to create new dataframe by looking for the string s1 in Question Key column
 df_temp <<- get(d) %>% group_by(`PID`) %>% filter(str_detect(`Question Key`, s1) == TRUE) %>% mutate("{s1}" := mean(Response)) %>% select(PID, session, {s1}) %>% distinct()
 if (nrow(df_temp) == 0) return(NULL) #if no data in dataframe (ie. string s1 doesn't exist in this dataframe) then end function
 assign(nam, df_temp, envir = .GlobalEnv) #otherwise assign new dataframe to global environment ie. outside of local function
}

# Apply this function across all dataframes and variable names
for (i in 1:length(var_names)) {
lapply(dflist, fn_var, s1 = var_names[i] )
}

# remove old dataframes
rm(list = dflist)
rm(df_temp)

#bind all common variables together
t1 <- rbind(att1, att2, att3, att4)
t2 <- rbind(behav1, behav4)
t3 <- rbind(cog1, cog2, cog3, cog4)
t4 <- rbind(diss1, diss2, diss3, diss4)
t5 <- rbind(emo_obj1, emo_obj2, emo_obj3, emo_obj4)
t6 <- rbind(emo1, emo2, emo3, emo4)
t7 <- rbind(hed1, hed2, hed3, hed4)
t8 <- rbind(moral1, moral2, moral3, moral4)
t9 <- rbind(pig1, pig2, pig3, pig4)

# create final dataframe by column binding t1-t9 matching by participant ID and session number
df <- plyr::join_all(list(t1, t2, t3, t4, t5, t6, t7, t8, t9, MIS1, HPRS1), by=c("PID", "session"), type='left') %>% ungroup()

# Standardise all variables
df[,3:13] <- scale(df[,3:13])

# Convert PID to factor from numeric
df$PID <- as.factor(df$PID)

# Remove any participants without complete data
complete <- df %>% select(PID, session) %>% pivot_wider(names_from = session, values_from = session) %>% na.omit() %>% select(PID) %>% pull()

df <- df %>% filter(PID %in% complete)

# have a nice cup of tea and a biscuit

```

## Power calculation
```{r, eval=FALSE, include=FALSE}

# simulate dataset based on 8 participants data to 1,000 ppts
  
for (i in 1:length(var_names4)) {
  df_temp <- sim_df(df, n = 1000, id ="PID", within = "session", dv = var_names4[i]) %>% pivot_longer(2:5, names_to = "session", values_to = var_names4[i])
  # Add new data frame from this file to overall data frame
  if (i == 1) {df_sim <- df_temp} else {df_sim <- merge(df_sim, df_temp, by = c("PID", "session"))}
}

df_sim$PID <- as.factor(df_sim$PID)
df_sim$session <- as.numeric(df_sim$session)

m_sim <- lmer(moral ~ session + (session|PID), data = df_sim)

fixef(m_sim)["pig"] <- 0.2
fixef(m_sim)["emo"] <- 0.2
fixef(m_sim)["att"] <- 0.2

powerSim(fit = m_sim, nsim = 100)
 
# simr::powerSim(fit = m_sim, test = compare(m_sim_null, method = "lr"), nsim = 100)

```





## Assumption checks
```{r}

# plots of variables by session


# Normality: Shapiro-Wilk test (note: test has limit of 5,000 samples so dataframe has to be done in parts)


for (i in 1:4) {
for (j in 1:length(var_names4)) {
  print(paste0("Session number ",i,", variable  ",var_names4[j]))
tmp <- shapiro.test(df[df$session == i,var_names4[j]])
if (tmp$p.value < .05) print(shapiro.test(df[,var_names4[j]]))
else print("NORMAL")}
}



# Normality QQ plots
qq_fn <- function(x, y) qqPlot(x, main = paste(y, "QQ Plot", sep = " "))
#par(mfrow = c(1, 2))
mapply(qq_fn, df, labels)


```

## Data visualisation
```{r}

# Scatter plots e.g. moral piggybacking vs moralisation at time 1, moral piggybacking vs moralisation at time 4 etc
# DO THESE

# Plot of key variables grand mean over each time point

df %>% select(PID, session, var_names4) %>% 
  pivot_longer(cols = !PID & !session, names_to = "variable", values_to = "value") %>%
  group_by(session, variable) %>% transmute(value = mean(value)) %>% unique() %>%
  ggplot(aes(x = session, y = value)) + geom_point(aes(color = variable), size = 3) +
  geom_line(aes(color = variable), size = 1.3) +
  scale_color_brewer(palette = "Spectral") + theme_bw()

# Plot of each variable by participant

# create function
spag_plot <- function(x) {
  df %>% select(PID, session, x) %>% 
  pivot_longer(cols = !PID & !session, names_to = "variable", values_to = "value") %>% 
  group_by(PID, session) %>% transmute(value = mean(value)) %>%
  ggplot(aes(x = session, y = value, group = PID)) + geom_point(size = 2) +
  geom_line(size = 0.5) + theme_bw() + ggtitle(x)
}

lapply(var_names4, spag_plot)

# Random slopes per participant
xyplot(moral ~ session|PID, data = df, type = c("r", "p"), xlim = c("1", "2", "3", "4"))

# Interaction plot
interaction.plot(df$session, df$PID, df$moral, legend = FALSE)


```

## Hypothesis testing
```{r}

# HYPOTHESIS 1: The change in moralisation, from the first measurement in session 1 to the final measurement in session 4, is predicted by moral emotions and moral piggybacking as measured by positive bi-variate correlation > 0.3.

# Calculate overall change in moralisation across whole sample at session 4 from session 1
(df %>% filter(session == 4) %>% transmute(m = mean(moral)) %>% unique()) %>% pull() - 
  (df %>% filter(session == 1) %>% transmute(m = mean(moral)) %>% unique() %>% pull())

# Add mean of each variable measure per participant per session to dataframe
df <- df %>% group_by(PID, session) %>% mutate(sess_moral_mean = mean(moral)) %>% ungroup()
df <- df %>% group_by(PID, session) %>% mutate(sess_pig_mean = mean(pig)) %>% ungroup()
df <- df %>% group_by(PID, session) %>% mutate(sess_emo_mean = mean(emo)) %>% ungroup()

#show in dataframe
df %>% select(PID, session,sess_moral_mean, sess_pig_mean, sess_emo_mean)

# Correlation of change in moralisation versus change in moral piggybacking
cor.test (pull(df %>% filter(session == 4) %>% select(sess_moral_mean) - df %>% filter(session == 1) %>% select(sess_moral_mean)), pull(df %>% filter(session ==4) %>% select(sess_pig_mean) - df %>% filter(session ==1) %>% select(sess_pig_mean)))

# Correlation of change in moralisation versus change in moral emotions
cor.test (pull(df %>% filter(session ==4) %>% select(sess_moral_mean) - df %>% filter(session == 1) %>% select(sess_moral_mean)), pull(df %>% filter(session ==4) %>% select(sess_emo_mean) - df %>% filter(session ==1) %>% select(sess_emo_mean)))

# HYPOTHESIS 2: The change in moralisation, from the first measurement in session 1 to the final measurement in session 4, is predicted most effectively by only moral emotions and moral piggybacking.

# Calculate change in moralisation session 4 - session 1 per participant and add to dataframe = DEPENDENT VARIABLE
df <- merge(df %>% filter(session == 4) %>% select(PID, sess_moral_mean), df %>%
        filter(session == 1) %>% select(PID, sess_moral_mean), by = "PID") %>%
        mutate(moral_delta = sess_moral_mean.x - sess_moral_mean.y) %>% 
        select(PID, moral_delta) %>%
        merge(., df, by = "PID")

# Calculate change in moral piggybacking session 4 - session 1 per participant and add to dataframe
df <- merge(df %>% filter(session == 4) %>% select(PID, sess_pig_mean), df %>%
        filter(session == 1) %>% select(PID, sess_pig_mean), by = "PID") %>%
        mutate(pig_delta = sess_pig_mean.x - sess_pig_mean.y) %>% 
        select(PID, pig_delta) %>%
        merge(., df, by = "PID")

# Calculate change in moral emotions session 4 - session 1 per participant and add to dataframe
df <- merge(df %>% filter(session == 4) %>% select(PID, sess_emo_mean), df %>%
        filter(session == 1) %>% select(PID, sess_emo_mean), by = "PID") %>%
        mutate(emo_delta = sess_emo_mean.x - sess_emo_mean.y) %>% 
        select(PID, emo_delta) %>%
        merge(., df, by = "PID")

# Simple linear regression model shows significant effects for both Moral Emotions and Moral Piggybacking
m1 <- lm(moral_delta ~ pig_delta + emo_delta, data = df)
summary(m1)
plot(m1)
performance::check_model(m1)









```

# Exploratory analyses I - multi-variate and mixed models
```{r}


# Modelling effect of time
m2 <- lm(moral ~ session, df)
summary(m2)
plot(m2)

m3 <- lm(moral ~ session + emo, df)
summary(m3)
plot(m3)

m4 <- lm(moral ~ session + emo + pig, df)
summary(m4)
plot(m4)

# Adding attitude measure shows that moral emotions and piggybacking account for variance and predict moralisation better

m5 <- lm(moral ~ session + emo + att, df)
summary(m5)
plot(m5)

m5 <- lm(moral ~ session + emo + att + pig, df)
summary(m5)
plot(m5)

# MIXED MODELS

# NOTE: to to do the mixed models accurately session should be converted to a continuous time variable

# Null model
m1 <- lmer(moral ~ session|PID, data = df)
summary(m1)
plot(m1)

# Create linear model with independent predictors
m2 <- lmer(moral ~ emo + (session|PID), data = df)
summary(m2)
plot(m2)

anova(m1, m2)

m3 <- lmer(moral ~ pig + (session|PID), data = df)
summary(m3)
plot(m3)
anova(m1, m3)

# this model has singularity issue:
m4 <- lmer(moral ~ session + pig + (session|PID), data = df)
summary(m4)



```

## Exploratory Analyses II - mediating variables
```{r}

# Influence of MIS on moralisation
working.data <- df %>% filter(session == 1 | session == 4)

m2 <- lmer(moral ~ MIS + (session|PID), data = working.data)
summary(m2)



# Influence of HPRS on moralisation and relationship to dissonance reduction


# Effects on behavioural intentions of all variables (correlation matrix)
```


# CROSS-LAGGED PANEL ANALYSIS
```{r}
# make dataframe into wide format

df %>% select(PID, moral, session, emo) %>% pivot_wider(id_cols = PID, names_from = session, values_from = c(moral, emo)) %>% select(-PID)


## extract data to work with -- m = moralization, e = meat emotions ##
working.data <- df %>% select(PID, moral, session, emo) %>% pivot_wider(id_cols = PID, names_from = session, values_from = c(moral, emo)) %>% select(-PID)
names(working.data) <- c('m1', 'm2', 'm3', 'm4', 'e1', 'e2', 'e3', 'e4')

names(working.data)


cross.second <- '
m2 ~ m1 + b1*e1
m3 ~ m2 + b2*e2 + m1
m4 ~ m3 + b3*e3 + m2

e2 ~ e1 + b4*m1
e3 ~ e2 + b5*m2 + e1
e4 ~ e3 + b6*m3 + e2

m1 ~~ e1
m2 ~~ e2
m3 ~~ e3
m4 ~~ e4

bb14 := b1-b4
bb25 := b2-b5
bb36 := b3-b6'

cross.second.fit <- lavaan(cross.second, data = working.data, auto.var = TRUE, fixed.x=FALSE) ## run model
summary(cross.second.fit, standardized = TRUE, fit.measures = TRUE) ## examine model


```

