---
title: "Moralisation_MAIN"
author: "Paul V"
date: "10/06/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries
```{r, message=FALSE}

library(kableExtra)
library(psych)
library(tidyverse)


```


## Import dummy data
```{r, message=FALSE}

setwd("C:/Users/Ben 10/Documents/Paul COG NEURO MSc/Empirical project/MAIN study dummy data") 

# Find files and create list of them
files <- list.files(pattern = "questionnaire")

# Create individual dataframe for each questionnaire node
for(i in seq(1, length(files), 5)) { #set up for loop in increments of 5 there are 5 dummy ppts
  nam <- paste("n_", substring(files[i], 20, 23), sep = "") #create a name for each question matching Gorilla node name
  #create dataframe called df within the loop which binds the 5 sequential participant files together
    df_temp <- rbind(read_csv(files[i]), read_csv(files[i+1]),  read_csv(files[i+2]),read_csv(files[i+3]),read_csv(files[i+4]))
    df_temp <- df_temp %>% filter(`Event Index` != "END OF FILE") %>%
    filter(`Question Key` != "END QUESTIONNAIRE" &  `Question Key` != "BEGIN QUESTIONNAIRE",
           !grepl("quantised", `Question Key`) ) %>%
  select(`Participant Private ID`, `Question Key`, Response, `Tree Node Key`)# remove all END OF FILE lines
    colnames(df_temp)[colnames(df_temp)=="Participant Private ID"] <- "PID"
    assign(nam, df_temp) #assign df to the name of the dataframe created above
}

#remove df_temp from workspace to prevent double counting
rm(df_temp)

```
## Data wrangle
```{r}



#create list of dataframes
dflist <- Filter(function(x) is.data.frame(get(x)), ls())

# Generic tidy up - remove beginning/end and quantised data lines, select only relevant columns
# for (i in 1:length(dflist)) {
# df_temp <- get(dflist[i]) %>% filter(`Question Key` != "END QUESTIONNAIRE" &  `Question Key` != "BEGIN QUESTIONNAIRE", !grepl("quantised", get(dflist[i])$`Question Key`)  ) %>% 
#   select(`Participant Private ID`, `Question Key`, Response, `Tree Node Key`) 
# rm()
# # Add new data frame from this file to overall data frame
#   if (i == 1) {df <- df_temp} else {df <- rbind(df, df_temp)}
# 
# }



# Rename PID column
# colnames(df)[colnames(df)=="Participant Private ID"] <- "PID"

#remove unnecessary dfs from environment
#rm(df_temp)
#rm(list = dflist)

# replace categorical answers with numeric
n_4kh5$Response <- str_replace_all(n_4kh5$Response, c(
    "Not at all opposed" = "1", "Slightly opposed" = "2", "Somewhat opposed" = "3", "Strongly opposed" = "4")) %>%
  as.numeric()

n_k47v$Response <- str_replace_all(n_k47v$Response, c(
    "Not at all opposed" = "1", "Slightly opposed" = "2", "Somewhat opposed" = "3", "Strongly opposed" = "4")) %>%
  as.numeric()

n_sjbg$Response <- str_replace_all(n_sjbg$Response, c(
    "Not at all opposed" = "1", "Slightly opposed" = "2", "Somewhat opposed" = "3", "Strongly opposed" = "4")) %>%
  as.numeric()

n_wxzl$Response <- str_replace_all(n_wxzl$Response, c(
    "Not at all opposed" = "1", "Slightly opposed" = "2", "Somewhat opposed" = "3", "Strongly opposed" = "4")) %>%
  as.numeric()


# Reverse score item MIS4
n_ubog[n_ubog$`Question Key` == "MIS4",'Response'] <- n_ubog %>% filter(`Question Key`== "MIS4") %>% select(Response) %>% transmute(Response = 6 - Response)

# Add session no. info to the dataframes
n_4kh5$session <- 2
n_5hpk$session <- 3
n_9opr$session <- 2
n_daab$session <- 2
n_fhoy$session <- 1
n_hhto$session <- 1
n_k47v$session <- 4
n_l8iw$session <- 4
n_lpz3$session <- 3
n_luva$session <- 3
n_okdo$session <- 1
n_p34a$session <- 1
n_sjbg$session <- 1
n_t7dh$session <- 1
n_txy2$session <- 2
n_ubog$session <- 1
n_vacc$session <- 3
n_wkz6$session <- 4
n_wxzl$session <- 3
n_xdo3$session <- 2
n_xuky$session <- 4
n_zd7j$session <- 2
n_zm3i$session <- 4


# Calculate mean scores for variables within individal dataframes (one variable / dataframe)
# Dissonance reduction

df %>% group_by(`PID`) %>% filter(str_detect(`Question Key`, "diss") == TRUE) %>% mutate(dissonance_reduction = mean(Response))
# Moral cognition



```

## Assumption checks
```{r}

# Reliability - Cronbach alpha

df %>% group_by(`Participant Private ID`) %>% filter(str_detect(`Question Key`, "diss") == TRUE) %>% mutate(alpha = psych::alpha(Response))

# Normality (Shapiro/QQ)





# Unifactorial scales - HPRS/MIS

# 


```

setwd("C:/Users/Ben 10/Documents/Paul COG NEURO MSc/Empirical project/MAIN study dummy data") 

#create list of dataframes
dflist <- Filter(function(x) is.data.frame(get(x)), ls())

# Generic tidy up - remove beginning/end and quantised data lines, select only relevant columns
for (i in 1:length(dflist)) {
df_temp <- get(dflist[i]) %>% filter(`Question Key` != "END QUESTIONNAIRE" &  `Question Key` != "BEGIN QUESTIONNAIRE", !grepl("quantised", get(dflist[i])$`Question Key`)  ) %>% select(`Participant Private ID`, `Question Key`, Response) 
rm()
# Add new data frame from this file to overall data frame
  if (i == 1) {df <- df_temp} else {df <- rbind(df, df_temp)}


