---
title: "Moralisation_MAIN"
author: "Paul V"
date: "10/06/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries
```{r, message=FALSE, warning=FALSE}

library(kableExtra)
library(psych)
library(car)
library(RColorBrewer)
library(lme4)
library(lattice)
library(faux)
library(simr)
library(rstatix)
library(ggpubr)
library(lavaan)
library(tidyverse)


```


## Import data
```{r, message = FALSE, warning=FALSE}

#clear workspace
rm(list = ls())

#laptop working directory
#setwd("/home/vanagpau/R/Moralisation/MAIN actual data") 

#desktop working directory
setwd("C:/Users/paulv/Documents/Paul COG NEURO MSc/Empirical project/MAIN actual data") 

# extract 4 character identifier for each questionnaire node
nam <- str_sub(list.files(pattern = "questionnaire"), -8, -5)

# combine all matching nodes: ONLY USE FOR NEW DATA
# for (i in seq(1:length(nam))) {
#   #read in each file, remove additional event as per text and combine all common questionnaire nodes
#   df_temp <- list.files(pattern = nam[i]) %>% lapply(read_csv, na = c("Unexpectedly long close out at end of task!", "NA")) %>% bind_rows()
#     df_temp <- df_temp %>% filter(`Event Index` != "END OF FILE") %>%
#     filter(`Question Key` != "END QUESTIONNAIRE" &  `Question Key` != "BEGIN QUESTIONNAIRE",
#            !grepl("quantised", `Question Key`) ) %>%
#   select(`Participant Private ID`, `Question Key`, Response, `Tree Node Key`)# remove all END OF FILE lines
#     colnames(df_temp)[colnames(df_temp)=="Participant Private ID"] <- "PID" #shorten col name to PID
#     assign(paste0("n_",nam[i]), df_temp) #assign df to the name of the dataframe created above
#     write_csv(df_temp, file = paste0("C:/Users/paulv/Documents/Paul COG NEURO MSc/Empirical project/Main study CSVs/","n_",nam[i],".csv"))
# }

# For existing data read in csv files for dataframes (much faster for knitting)
for (i in seq(1:length(unique(nam)))) {
  df_temp <- read_csv(paste0("C:/Users/paulv/Documents/Paul COG NEURO MSc/Empirical project/Main study CSVs/","n_",nam[i],".csv"))
  assign(paste0("n_",nam[i]), df_temp)
}

#remove unnecessary dfs from environment (consent, debrief nodes, explainer, survey code pages etc)
rm(n_1dbi,n_o3u2, n_q986, n_1dbi, n_8941, n_gbx3)

#remove df_temp from workspace to prevent double counting
rm(df_temp)

#create list of remaining dataframes (as strings)
dflist <- Filter(function(x) is.data.frame(get(x)), ls())

#INCOMPLETE CODE
#create list of remaining dataframe (as objects)
#lapply(ls(pattern="n_"), function(x) get(x))
#save to csv for quick recall in subsequent chunk
#lapply(dflist, write_csv, file = paste0(dflist,".csv"))

```
## Data wrangle
```{r}


# replace categorical answers with numeric
n_4kh5$Response <- str_replace_all(n_4kh5$Response, c(
    "Not at all opposed" = "1", "Slightly opposed" = "2", "Somewhat opposed" = "3", "Strongly opposed" = "4")) %>%
  as.numeric()
n_k47v$Response <- str_replace_all(n_k47v$Response, c(
    "Not at all opposed" = "1", "Slightly opposed" = "2", "Somewhat opposed" = "3", "Strongly opposed" = "4")) %>%
  as.numeric()
n_sjbg$Response <- str_replace_all(n_sjbg$Response, c(
    "Not at all opposed" = "1", "Slightly opposed" = "2", "Somewhat opposed" = "3", "Strongly opposed" = "4")) %>%
  as.numeric()
n_wxzl$Response <- str_replace_all(n_wxzl$Response, c(
    "Not at all opposed" = "1", "Slightly opposed" = "2", "Somewhat opposed" = "3", "Strongly opposed" = "4")) %>%
  as.numeric()



# Reverse score item MIS4
n_ubog[n_ubog$`Question Key` == "MIS4",'Response'] <- n_ubog %>% filter(`Question Key`== "MIS4") %>% select(Response) %>% transmute(Response = 6 - Response)

# Reverse score item diss7 (across 4 spreadsheet/nodes)
n_hhto[n_hhto$`Question Key` == "diss7",'Response'] <- n_hhto %>% filter(`Question Key`== "diss7") %>% select(Response) %>% transmute(Response = 6 - Response)
n_zd7j[n_zd7j$`Question Key` == "diss7",'Response'] <- n_zd7j %>% filter(`Question Key`== "diss7") %>% select(Response) %>% transmute(Response = 6 - Response)
n_luva[n_luva$`Question Key` == "diss7",'Response'] <- n_luva %>% filter(`Question Key`== "diss7") %>% select(Response) %>% transmute(Response = 6 - Response)
n_zm3i[n_zm3i$`Question Key` == "diss7",'Response'] <- n_zm3i %>% filter(`Question Key`== "diss7") %>% select(Response) %>% transmute(Response = 6 - Response)


# Add session no. info to the dataframes
n_4kh5$session <- 2
n_5hpk$session <- 3
n_9opr$session <- 2
n_auod$session <- 1
n_daab$session <- 2
n_fhoy$session <- 1
n_hhto$session <- 1
n_k47v$session <- 4
n_l8iw$session <- 4
n_lpz3$session <- 3
n_luva$session <- 3
n_okdo$session <- 1
n_p34a$session <- 1
n_sjbg$session <- 1
n_t7dh$session <- 1
n_txy2$session <- 2
n_ubog$session <- 1
n_vacc$session <- 3
n_wkz6$session <- 4
n_wxzl$session <- 3
n_xdo3$session <- 4
n_xuky$session <- 4
n_zd7j$session <- 2
n_zm3i$session <- 4

## Calculate mean scores for variables within individual dataframes (one variable / dataframe)

# create list of variable names to search for
var_names <- c("cog", "att", "pig", "hed", "HPRS", "moral", "diss", "emo", "emo_obj", "behav", "MIS")

# Cronbach alpha to check reliability of scales by session

# Create data frame where each column is a test/questionnaire item, each row is a person
df_all <- bind_rows(Filter(function(x) is(x, "data.frame"), mget(ls())))
df_all <- df_all %>% group_by(`PID`) %>% pivot_wider(id_cols = PID, names_from = c(`Question Key`, session), values_from = Response) %>% ungroup () 

# list of variables at all 4 time points
var_names4 <- c("cog", "att", "pig", "hed", "moral", "diss", "emo", "emo_obj")

# Run Cronbach alpha on each questionnaire - detected using regex string matching

# # Moral cognition 1
a1 <- psych::alpha(df_all[,str_detect(colnames(df_all), "cog.*?1$")])
summary(a1)
# Moral cognition 2
a2 <- psych::alpha(df_all[,str_detect(colnames(df_all), "cog.*?2$")])
summary(a2)
# Moral cognition 3
a3 <- psych::alpha(df_all[,str_detect(colnames(df_all), "cog.*?3$")])
summary(a3)
# Moral cognition 4
a4 <- psych::alpha(df_all[,str_detect(colnames(df_all), "cog.*?4$")])
summary(a4)
# Attitude 1
a5 <- psych::alpha(df_all[,str_detect(colnames(df_all), "att.*?1$")])
summary(a5)
# Attitude 2
a6 <- psych::alpha(df_all[,str_detect(colnames(df_all), "att.*?2$")])
summary(a6)
# Attitude 3
a7 <- psych::alpha(df_all[,str_detect(colnames(df_all), "att.*?3$")])
summary(a7)
# Attitude 4
a8 <- psych::alpha(df_all[,str_detect(colnames(df_all), "att.*?4$")])
summary(a8)
# Moral piggybacking 1
a9 <- psych::alpha(df_all[,str_detect(colnames(df_all), "pig.*?1$")])
summary(a9)
# Moral piggybacking 2
a10 <- psych::alpha(df_all[,str_detect(colnames(df_all), "pig.*?2$")])
summary(a10)
# Moral piggybacking 3
a11 <- psych::alpha(df_all[,str_detect(colnames(df_all), "pig.*?3$")])
summary(a11)
# Moral piggybacking 4
a12 <- psych::alpha(df_all[,str_detect(colnames(df_all), "pig.*?4$")])
summary(a12)
# Hedonic motivation 1
a13 <- psych::alpha(df_all[,str_detect(colnames(df_all), "hed.*?1$")])
summary(a13)
# Hedonic motivation 2
a14 <- psych::alpha(df_all[,str_detect(colnames(df_all), "hed.*?2$")])
summary(a14)
# Hedonic motivation 3
a15 <- psych::alpha(df_all[,str_detect(colnames(df_all), "hed.*?3$")])
summary(a15)
# Hedonic motivation 4
a16 <- psych::alpha(df_all[,str_detect(colnames(df_all), "hed.*?4$")])
summary(a16)
# Moralisation 1
a17 <- psych::alpha(df_all[,str_detect(colnames(df_all), "moral.*?1$")])
summary(a17)
# Moralisation 2
a18 <- psych::alpha(df_all[,str_detect(colnames(df_all), "moral.*?2$")])
summary(a18)
# Moralisation 3
a19 <- psych::alpha(df_all[,str_detect(colnames(df_all), "moral.*?3$")])
summary(a19)
# Moralisation 4
a20 <- psych::alpha(df_all[,str_detect(colnames(df_all), "moral.*?4$")])
summary(a20)
# Dissonance Reduction 1
a21 <- psych::alpha(df_all[,str_detect(colnames(df_all), "diss.*?1$")])
summary(a21)
# Dissonance Reduction 2
a22 <- psych::alpha(df_all[,str_detect(colnames(df_all), "diss.*?2$")])
summary(a22)
# Dissonance Reduction 3
a23 <- psych::alpha(df_all[,str_detect(colnames(df_all), "diss.*?3$")])
summary(a23)
# Dissonance Reduction 4
a24 <- psych::alpha(df_all[,str_detect(colnames(df_all), "diss.*?4$")])
summary(a24)
# Moral emotions 1
a25 <- psych::alpha(df_all[,str_detect(colnames(df_all), "emo.*?1$")])
summary(a25)
# Moral emotions 2
a26 <- psych::alpha(df_all[,str_detect(colnames(df_all), "emo.*?2$")])
summary(a26)
# Moral emotions 3
a27 <- psych::alpha(df_all[,str_detect(colnames(df_all), "emo.*?3$")])
summary(a27)
# Moral emotions 4
a28 <- psych::alpha(df_all[,str_detect(colnames(df_all), "emo.*?4$")])
summary(a28)
# Moral emotions (objects) 1
a29 <- psych::alpha(df_all[,str_detect(colnames(df_all), "emo_obj.*?1$")])
summary(a29)
# Moral emotions (objects) 2
a30 <- psych::alpha(df_all[,str_detect(colnames(df_all), "emo_obj.*?2$")])
summary(a30)
# Moral emotions (objects) 3
a31 <- psych::alpha(df_all[,str_detect(colnames(df_all), "emo_obj.*?3$")])
summary(a31)
# Moral emotions (objects) 4
a32 <- psych::alpha(df_all[,str_detect(colnames(df_all), "emo_obj.*?4$")])
summary(a32)

# HPRS
a33 <- psych::alpha(df_all[,str_detect(colnames(df_all), "HPRS")])
summary(a33)
# # MIS
a34 <- psych::alpha(df_all[,str_detect(colnames(df_all), "MIS")])
summary(a34)
# 
# # Behavioural intentions 1
a35 <- psych::alpha(df_all[,str_detect(colnames(df_all), "behav.*?1$")])
summary(a35)
# # Behavioural intentions 2
a36 <- psych::alpha(df_all[,str_detect(colnames(df_all), "behav.*?4$")])
summary(a36)



# Create function to calculate variable mean scores
fn_var <- function(d, s1) {
 nam <- paste0(s1, get(d)[1,5]) #create dataframe name from input dataframe and variable string
 #filter and mutate to create new dataframe by looking for the string s1 in Question Key column
 df_temp <<- get(d) %>% group_by(`PID`) %>% filter(str_detect(`Question Key`, s1) == TRUE) %>% mutate("{s1}" := mean(Response)) %>% select(PID, session, {s1}) %>% distinct()
 if (nrow(df_temp) == 0) return(NULL) #if no data in dataframe (ie. string s1 doesn't exist in this dataframe) then end function
 assign(nam, df_temp, envir = .GlobalEnv) #otherwise assign new dataframe to global environment ie. outside of local function
}

# Apply this function across all dataframes and variable names
for (i in 1:length(var_names)) {
lapply(dflist, fn_var, s1 = var_names[i] )
}

# remove old dataframes
rm(list = dflist)
rm(df_temp)

#bind all common variables together
t1 <- rbind(att1, att2, att3, att4)
t2 <- rbind(behav1, behav4)
t3 <- rbind(cog1, cog2, cog3, cog4)
t4 <- rbind(diss1, diss2, diss3, diss4)
t5 <- rbind(emo_obj1, emo_obj2, emo_obj3, emo_obj4)
t6 <- rbind(emo1, emo2, emo3, emo4)
t7 <- rbind(hed1, hed2, hed3, hed4)
t8 <- rbind(moral1, moral2, moral3, moral4)
t9 <- rbind(pig1, pig2, pig3, pig4)

# create final dataframe by column binding t1-t9 matching by participant ID and session number
df <- plyr::join_all(list(t1, t2, t3, t4, t5, t6, t7, t8, t9, MIS1, HPRS1), by=c("PID", "session"), type='left') %>% ungroup()

# Standardise all variables
df[,3:13] <- scale(df[,3:13])

# Convert PID to factor from numeric
df$PID <- as.factor(df$PID)

# Remove any participants without complete data
complete <- df %>% select(PID, session) %>% pivot_wider(names_from = session, values_from = session) %>% na.omit() %>% select(PID) %>% pull()

df <- df %>% filter(PID %in% complete)

# report number of participants in analysis
length(unique(df$PID))

# have a nice cup of tea and a biscuit

```

## Power calculation
```{r, eval=FALSE, include=FALSE}

# simulate dataset based on 8 participants data to 1,000 ppts
  
for (i in 1:length(var_names4)) {
  df_temp <- sim_df(df, n = 1000, id ="PID", within = "session", dv = var_names4[i]) %>% pivot_longer(2:5, names_to = "session", values_to = var_names4[i])
  # Add new data frame from this file to overall data frame
  if (i == 1) {df_sim <- df_temp} else {df_sim <- merge(df_sim, df_temp, by = c("PID", "session"))}
}

df_sim$PID <- as.factor(df_sim$PID)
df_sim$session <- as.numeric(df_sim$session)

m_sim <- lmer(moral ~ session + (session|PID), data = df_sim)

fixef(m_sim)["pig"] <- 0.2
fixef(m_sim)["emo"] <- 0.2
fixef(m_sim)["att"] <- 0.2

powerSim(fit = m_sim, nsim = 100)
 
# simr::powerSim(fit = m_sim, test = compare(m_sim_null, method = "lr"), nsim = 100)

```





## Assumption checks
```{r}

# plots of variables by session
# ggplot(df[df$session == 4,var_names4[8]], aes(x=emo_obj)) + geom_histogram(binwidth = .5)


# Normality: Shapiro-Wilk test per variable mean per session and plot histograms of each distribution for variables collected at all 4 time points (var_names4)

for (i in 1:4) {
for (j in 1:length(var_names4)) {
tmp <- shapiro.test(pull(df[df$session == i,var_names4[j]]))
print(paste0("Session number ",i,", variable  ",var_names4[j]))
if (tmp$p.value < .05) {print(tmp)
  print(ggplot(df[df$session == i,var_names4[j]], aes(x=get(var_names4[j]))) +
        geom_histogram(binwidth = .3) + ggtitle(paste0("Session ",i)) +
  xlab(var_names4[j]))}
else  print(tmp)
}
}

# Shapiro-Wilk test for other variables (HPRS, MIS, behavioural intentions)
shapiro.test(pull(df[df$session == 1,"HPRS"]))
shapiro.test(pull(df[df$session == 1,"MIS"]))
shapiro.test(pull(df[df$session == 1,"behav"]))
shapiro.test(pull(df[df$session == 4,"behav"]))

#Plots for other variables (HPRS, MIS, behavioural intentions)
ggplot(df[df$session == 1,"HPRS"], aes(x=HPRS)) +
  geom_histogram(binwidth = .5) +
  ggtitle(paste0("Session ",1)) + xlab("HPRS")

ggplot(df[df$session == 1,"MIS"], aes(x=MIS)) +
  geom_histogram(binwidth = .5) +
  ggtitle(paste0("Session ",1)) + xlab("MIS")

ggplot(df[df$session == 1,"behav"], aes(x=behav)) +
  geom_histogram(binwidth = .5) +
  ggtitle(paste0("Session ",1)) + xlab("behav")

ggplot(df[df$session == 4,"behav"], aes(x=behav)) +
  geom_histogram(binwidth = .5) +
  ggtitle(paste0("Session ",4)) + xlab("behav")


# Normality QQ plots for for variables collected at all 4 time points (var_names4)

qq_fn <- function(x, y) qqPlot(x, main = paste(y, "QQ Plot", sep = " ", "Session", i))

for (i in 1:4) {
mapply(qq_fn, df %>% filter(session == i) %>% select(-session, -PID, -behav, -MIS, -HPRS), var_names4)
}

```

## Data visualisation
```{r}

# Scatter plots 

# create scatter plot function
#df %>% ggplot(aes(x = att, y = moral)) + geom_smooth(method = lm) + geom_point() + facet_wrap(~session)

scat <- function (x, y) {df %>% 
    ggplot(aes_string(x = x, y = y)) + geom_smooth(method = lm) + geom_point() + facet_wrap(~session)}

# Apply to all 4 time-point variables with moralisation as y-variable
lapply(var_names4, scat, y = "moral")

# Scatter plot of moralisation at time 1 vs behavioural intentions at time 1
df %>% filter(session == 1) %>% select(moral, behav) %>% ggplot(aes(x = behav, y = moral)) + geom_point() + geom_smooth(method = lm)
# Correlation
df %>% filter(session == 1) %>% select(moral, behav) %>% cor_test(moral, behav)

# Scatter plot of moralisation at time 4 vs behavioural intentions at time 4
df %>% filter(session == 4) %>% select(moral, behav) %>% ggplot(aes(x = behav, y = moral)) + geom_point() + geom_smooth(method = lm)
# Correlation
df %>% filter(session == 4) %>% select(moral, behav) %>% cor_test(moral, behav)

# Scatter plot of dissonance reduction at time 1 vs behavioural intentions at time 1
df %>% filter(session == 1) %>% select(diss, behav) %>% ggplot(aes(x = diss, y = behav)) + geom_point() + geom_smooth(method = lm)
# Correlation
df %>% filter(session == 1) %>% select(diss, behav) %>% cor_test(diss, behav)

# Scatter plot of dissonance reduction at time 4 vs behavioural intentions at time 4
df %>% filter(session == 4) %>% select(diss, behav) %>% ggplot(aes(x = diss, y = behav)) + geom_point() + geom_smooth(method = lm)
# Correlation
df %>% filter(session == 4) %>% select(diss, behav) %>% cor_test(diss, behav)

# Dissonance reduction has a MORE NEGATIVE correlation with behavioural intention at time 4 versus time 1
# So test to see if difference in r values is significant = NO
paired.r(-.35, -.48, n = 43)

# Plot of key variables grand mean over each time point

df %>% select(PID, session, var_names4) %>% 
  pivot_longer(cols = !PID & !session, names_to = "variable", values_to = "value") %>%
  group_by(session, variable) %>% transmute(value = mean(value)) %>% unique() %>%
  ggplot(aes(x = session, y = value)) + geom_point(aes(color = variable), size = 3) +
  geom_line(aes(color = variable), size = 1.3) +
  scale_color_brewer(palette = "Spectral") + theme_bw()

# create vector of session 1 means to use in rebased chart
session1 <- rep(df %>% select(PID, session, var_names4) %>% 
  pivot_longer(cols = !PID & !session, names_to = "variable", values_to = "value") %>%
  group_by(session, variable) %>% transmute(value = mean(value)) %>% unique() %>% ungroup() %>% 
  filter (session == 1) %>% select(value) %>% pull(), times = 4)

#Create rebased chart
df %>% select(PID, session, var_names4) %>% 
  pivot_longer(cols = !PID & !session, names_to = "variable", values_to = "value") %>%
  group_by(session, variable)  %>% transmute(value = mean(value)) %>%  unique() %>% cbind(session1) %>%
  transmute(value = value - ...4) %>%
  ggplot(aes(x = session, y = value)) + geom_point(aes(color = variable), size = 3) +
  geom_line(aes(color = variable), size = 1.3) +
  scale_color_brewer(palette = "Spectral") + theme_bw()


# Plot of each variable by participant

# create function for spaghetti plots - note: these don't really show anything
# spag_plot <- function(x) {
#   df %>% select(PID, session, x) %>% 
#   pivot_longer(cols = !PID & !session, names_to = "variable", values_to = "value") %>% 
#   group_by(PID, session) %>% transmute(value = mean(value)) %>%
#   ggplot(aes(x = session, y = value, group = PID)) + geom_point(size = 2) +
#   geom_line(size = 0.5) + theme_bw() + ggtitle(x)
# }
# 
# lapply(var_names4, spag_plot)

# Random slopes per participant
xyplot(moral ~ session|PID, data = df, type = c("r", "p"), xlim = c("1", "2", "3", "4"))

# Interaction plot
#interaction.plot(df$session, df$PID, df$moral, legend = FALSE)


```

## Hypothesis testing
```{r}

# HYPOTHESIS 1: The change in moralisation, from the first measurement in session 1 to the final measurement in session 4, is predicted by moral emotions and moral piggybacking as measured by positive bi-variate correlation > 0.3.

# Calculate overall change in moralisation across whole sample at session 4 from session 1
# (df %>% filter(session == 4) %>% transmute(m = mean(moral)) %>% unique()) %>% pull() - 
#   (df %>% filter(session == 1) %>% transmute(m = mean(moral)) %>% unique() %>% pull())

# Add mean of each variable measure per participant per session to dataframe
df <- df %>% group_by(PID, session) %>% mutate(sess_moral_mean = mean(moral)) %>% ungroup()
df <- df %>% group_by(PID, session) %>% mutate(sess_pig_mean = mean(pig)) %>% ungroup()
df <- df %>% group_by(PID, session) %>% mutate(sess_emo_mean = mean(emo)) %>% ungroup()
df <- df %>% group_by(PID, session) %>% mutate(sess_behav_mean = mean(behav)) %>% ungroup()

#show in dataframe
df %>% select(PID, session,sess_moral_mean, sess_pig_mean, sess_emo_mean)

# Calculate change in moralisation session 4 - session 1 per participant and add to dataframe = DEPENDENT VARIABLE
df <- merge(df %>% filter(session == 4) %>% select(PID, sess_moral_mean), df %>%
        filter(session == 1) %>% select(PID, sess_moral_mean), by = "PID") %>%
        mutate(moral_delta = sess_moral_mean.x - sess_moral_mean.y) %>% 
        select(PID, moral_delta) %>%
        merge(., df, by = "PID")

# Calculate change in moral piggybacking session 4 - session 1 per participant and add to dataframe
df <- merge(df %>% filter(session == 4) %>% select(PID, sess_pig_mean), df %>%
        filter(session == 1) %>% select(PID, sess_pig_mean), by = "PID") %>%
        mutate(pig_delta = sess_pig_mean.x - sess_pig_mean.y) %>% 
        select(PID, pig_delta) %>%
        merge(., df, by = "PID")

# Calculate change in moral emotions session 4 - session 1 per participant and add to dataframe
df <- merge(df %>% filter(session == 4) %>% select(PID, sess_emo_mean), df %>%
        filter(session == 1) %>% select(PID, sess_emo_mean), by = "PID") %>%
        mutate(emo_delta = sess_emo_mean.x - sess_emo_mean.y) %>% 
        select(PID, emo_delta) %>%
        merge(., df, by = "PID")

# # Calculate change in behavioural intentions session 4 - session 1 per participant and add to dataframe
df <- merge(df %>% filter(session == 4) %>% select(PID, sess_behav_mean), df %>%
        filter(session == 1) %>% select(PID, sess_behav_mean), by = "PID") %>%
        mutate(behav_delta = sess_behav_mean.x - sess_behav_mean.y) %>% 
        select(PID, behav_delta) %>%
        merge(., df, by = "PID")

# Scatter plots
df %>% ggplot(aes(x = emo_delta, y = moral_delta)) + geom_point() + geom_smooth(method = lm)
df %>% ggplot(aes(x = pig_delta, y = moral_delta)) + geom_point() + geom_smooth(method = lm)
df %>% ggplot(aes(x = behav_delta, y = moral_delta)) + geom_point() + geom_smooth(method = lm)

# Correlation of change in moralisation versus change in moral piggybacking
cor.test (pull(df %>% filter(session == 4) %>% select(sess_moral_mean) - df %>% filter(session == 1) %>% select(sess_moral_mean)), pull(df %>% filter(session ==4) %>% select(sess_pig_mean) - df %>% filter(session ==1) %>% select(sess_pig_mean)))

# Correlation of change in moralisation versus change in moral emotions
cor.test (pull(df %>% filter(session ==4) %>% select(sess_moral_mean) - df %>% filter(session == 1) %>% select(sess_moral_mean)), pull(df %>% filter(session ==4) %>% select(sess_emo_mean) - df %>% filter(session ==1) %>% select(sess_emo_mean)))

# HYPOTHESIS 2: The change in moralisation, from the first measurement in session 1 to the final measurement in session 4, is predicted most effectively by only moral emotions and moral piggybacking.

# Simple linear regression model shows significant effects for both Moral Emotions and Moral Piggybacking
m1 <- lm(moral_delta ~ pig_delta + emo_delta, data = df)
summary(m1)
performance::check_model(m1)
AIC(m1)

# Modelling effect of time = session has significant effect (p = 0.02), but small (coeff = 0.15)
m2 <- lm(moral ~ session, df)
summary(m2)
performance::check_model(m2)
AIC(m2)

m3 <- lm(moral ~ session + emo, df)
summary(m3)
performance::check_model(m3)
AIC(m3)

m4 <- lm(moral ~ session + emo + pig, df)
summary(m4)
performance::check_model(m4)
AIC(m4)

# Adding attitude measure shows that moral emotions and piggybacking account for variance and predict moralisation better, this is important because it differentiates moralisation from attitude change

m5 <- lm(moral ~ session + emo + att, df)
summary(m5)
performance::check_model(m5)
AIC(m5)

m6 <- lm(moral ~ session + pig + att, df)
summary(m6)
performance::check_model(m6)
AIC(m6)

m7 <- lm(moral ~ session + emo + att + pig, df)
summary(m7)
performance::check_model(m7)
AIC(m7)

m8 <- lm(moral ~ session + emo + pig, df)
summary(m8)
performance::check_model(m8)
AIC(m8)

# try fitting other models with additional variable

# Hedonic motivation - does not add anything
m9 <- lm(moral ~ session + emo + pig + hed, df)
summary(m9)
performance::check_model(m9)
AIC(m9)

# Moral cognitions is significant and absorbs some Moral Emotions variance. m10 AIC score lower than m4
m10 <- lm(moral ~ session + emo + pig + cog, df)
summary(m10)
performance::check_model(m10)
AIC(m10)

# Do Moral emotions and Moral emotions with regard to people (emo_obj) explain different variance? Answer is no - emo-Obj not significant when emo present
m11 <- lm(moral ~ session + emo + emo_obj, df)
summary(m11)
performance::check_model(m11)
AIC(m11)

# this is confirmed by adding into best model to date (m10)
m12 <- lm(moral ~ session + emo + pig + cog + emo_obj, df)
summary(m12)
performance::check_model(m12)
AIC(m12)

# test cognitive dissonance - no significant effect
m13 <- lm(moral ~ session + emo + pig + cog + diss, df)
summary(m13)
performance::check_model(m13)
AIC(m13)

# test traits - Moral self-identity
cor.test(pull(df %>% filter(session == 1) %>% select(MIS)), pull(df %>% filter(session == 1) %>% select(moral_delta)))

# test traits - Psychological reactance
cor.test(pull(df %>% filter(session == 1) %>% select(HPRS)), pull(df %>% filter(session == 1) %>% select(moral_delta)))

# REPEATED MEASURES ANOVA
# Test assumptions; 1. Outliers - some outliers but none of them extreme (Values above Q3 + 3xIQR or below Q1 - 3xIQR are considered as extreme)

for (i in 1:4){
  for (j in 1:length(var_names4)) {
print(identify_outliers(df %>% filter(session == i) %>% select(var_names4[j])))
  }
}

# 2. Normality - moralisation is non-normal at times points 3 and 4 (see Assumptions section above)

# 3. Mauchly's test of sphericity is conducted when anova_test used

df %>% group_by(session) %>% get_summary_stats(moral, type = "mean_sd")
ggboxplot(df, x = "session", y = c("moral"), add = "jitter")

# Repeated measures ANOVA shows significant, but small effect of time (GES = generalised effect size https://www.psy.gla.ac.uk/~steve/best/effect.html)
rep.a1 <- anova_test(data = df, dv = moral, wid = PID, within = session)
get_anova_table(rep.a1)

# Multiple pair-wise t-tests show that moralisation significant from session 1 to 3 and 1 to 4
df %>%  pairwise_t_test(moral ~ session, paired = TRUE,p.adjust.method = "bonferroni")


```

# Exploratory analyses I - mixed models
```{r}


# MIXED MODELS

# NOTE: to do the mixed models accurately session should time be converted to a continuous variable??

# Null model
m1 <- lmer(moral ~ session|PID, data = df)
summary(m1)
performance::check_model(m1)

# Create linear model with independent predictors
m2 <- lmer(moral ~ emo + (session|PID), data = df)
summary(m2)
plot(m2)

anova(m1, m2)

m3 <- lmer(moral ~ pig + (session|PID), data = df)
summary(m3)
plot(m3)
anova(m1, m3)


m4 <- lmer(moral ~ session + pig + emo + (session|PID), data = df)
summary(m4)



```

## Exploratory Analyses II - mediating variables
```{r, include=TRUE, eval=FALSE}

# Influence of MIS on moralisation
working.data <- df %>% filter(session == 1 | session == 4)

m2 <- lmer(moral ~ MIS + (session|PID), data = working.data)
summary(m2)



# Influence of HPRS on moralisation and relationship to dissonance reduction


# Effects on behavioural intentions of all variables (correlation matrix)
```


# Exploratory Analyses III: Cross-lagged panel analysis
```{r}

# 1. MORALISATION and MORAL EMOTIONS

# make dataframe into wide format
df %>% select(PID, moral, session, emo) %>% pivot_wider(id_cols = PID, names_from = session, values_from = c(moral, emo)) %>% select(-PID)


## extract data to work with -- m = moralization, e = moral emotions ##
working.data <- df %>% select(PID, moral, session, emo) %>% pivot_wider(id_cols = PID, names_from = session, values_from = c(moral, emo)) %>% select(-PID)
names(working.data) <- c('m1', 'm2', 'm3', 'm4', 'e1', 'e2', 'e3', 'e4')

names(working.data)


cross.1 <- '
m2 ~ m1 + b1*e1
m3 ~ m2 + b2*e2 + m1
m4 ~ m3 + b3*e3 + m2

e2 ~ e1 + b4*m1
e3 ~ e2 + b5*m2 + e1
e4 ~ e3 + b6*m3 + e2

m1 ~~ e1
m2 ~~ e2
m3 ~~ e3
m4 ~~ e4

bb14 := b1-b4
bb25 := b2-b5
bb36 := b3-b6'

cross.1.fit <- lavaan(cross.1, data = working.data, auto.var = TRUE, fixed.x=FALSE) ## run model
summary(cross.1.fit, standardized = TRUE, fit.measures = TRUE) ## examine model

# 2. MORALISATION and MORAL PIGGYBACKING


# make dataframe into wide format
df %>% select(PID, moral, session, pig) %>% pivot_wider(id_cols = PID, names_from = session, values_from = c(moral, pig)) %>% select(-PID)


## extract data to work with -- m = moralization, e = moral piggybacking ##
working.data <- df %>% select(PID, moral, session, pig) %>% pivot_wider(id_cols = PID, names_from = session, values_from = c(moral, pig)) %>% select(-PID)
names(working.data) <- c('m1', 'm2', 'm3', 'm4', 'e1', 'e2', 'e3', 'e4')

names(working.data)


cross.2 <- '
m2 ~ m1 + b1*e1
m3 ~ m2 + b2*e2 + m1
m4 ~ m3 + b3*e3 + m2

e2 ~ e1 + b4*m1
e3 ~ e2 + b5*m2 + e1
e4 ~ e3 + b6*m3 + e2

m1 ~~ e1
m2 ~~ e2
m3 ~~ e3
m4 ~~ e4

bb14 := b1-b4
bb25 := b2-b5
bb36 := b3-b6'

cross.2.fit <- lavaan(cross.2, data = working.data, auto.var = TRUE, fixed.x=FALSE) ## run model
summary(cross.2.fit, standardized = TRUE, fit.measures = TRUE) ## examine model


```

