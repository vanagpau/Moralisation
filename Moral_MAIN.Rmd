---
title: "Moralisation_MAIN"
author: "Paul V"
date: "10/06/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries
```{r, message=FALSE}

library(kableExtra)
library(psych)
library(tidyverse)


```


## Import dummy data
```{r, message=FALSE}

#clear workspace
rm(list = ls())

setwd("C:/Users/Ben 10/Documents/Paul COG NEURO MSc/Empirical project/MAIN study dummy data") 

# Find files and create list of them
files <- list.files(pattern = "questionnaire")

# Create individual dataframe for each questionnaire node
for(i in seq(1, length(files), 5)) { #set up for loop in increments of 5 there are 5 dummy ppts
  nam <- paste("n_", substring(files[i], 20, 23), sep = "") #create a name for each question matching Gorilla node name
  #create dataframe called df within the loop which binds the 5 sequential participant files together
    df_temp <- rbind(read_csv(files[i]), read_csv(files[i+1]),  read_csv(files[i+2]),read_csv(files[i+3]),read_csv(files[i+4]))
    df_temp <- df_temp %>% filter(`Event Index` != "END OF FILE") %>%
    filter(`Question Key` != "END QUESTIONNAIRE" &  `Question Key` != "BEGIN QUESTIONNAIRE",
           !grepl("quantised", `Question Key`) ) %>%
  select(`Participant Private ID`, `Question Key`, Response, `Tree Node Key`)# remove all END OF FILE lines
    colnames(df_temp)[colnames(df_temp)=="Participant Private ID"] <- "PID"
    assign(nam, df_temp) #assign df to the name of the dataframe created above
}

#remove df_temp from workspace to prevent double counting
rm(df_temp)

```
## Data wrangle 1
```{r}

# Generic tidy up - remove beginning/end and quantised data lines, select only relevant columns
# for (i in 1:length(dflist)) {
# df_temp <- get(dflist[i]) %>% filter(`Question Key` != "END QUESTIONNAIRE" &  `Question Key` != "BEGIN QUESTIONNAIRE", !grepl("quantised", get(dflist[i])$`Question Key`)  ) %>% 
#   select(`Participant Private ID`, `Question Key`, Response, `Tree Node Key`) 
# rm()
# # Add new data frame from this file to overall data frame
#   if (i == 1) {df <- df_temp} else {df <- rbind(df, df_temp)}
# 
# }

#remove unnecessary dfs from environment (consent, debrief nodes etc)
rm(n_1dbi,n_o3u2, n_q986)

#create list of remaining dataframes
dflist <- Filter(function(x) is.data.frame(get(x)), ls())

# replace categorical answers with numeric
n_4kh5$Response <- str_replace_all(n_4kh5$Response, c(
    "Not at all opposed" = "1", "Slightly opposed" = "2", "Somewhat opposed" = "3", "Strongly opposed" = "4")) %>%
  as.numeric()
n_k47v$Response <- str_replace_all(n_k47v$Response, c(
    "Not at all opposed" = "1", "Slightly opposed" = "2", "Somewhat opposed" = "3", "Strongly opposed" = "4")) %>%
  as.numeric()
n_sjbg$Response <- str_replace_all(n_sjbg$Response, c(
    "Not at all opposed" = "1", "Slightly opposed" = "2", "Somewhat opposed" = "3", "Strongly opposed" = "4")) %>%
  as.numeric()
n_wxzl$Response <- str_replace_all(n_wxzl$Response, c(
    "Not at all opposed" = "1", "Slightly opposed" = "2", "Somewhat opposed" = "3", "Strongly opposed" = "4")) %>%
  as.numeric()

# Reverse score item MIS4
n_ubog[n_ubog$`Question Key` == "MIS4",'Response'] <- n_ubog %>% filter(`Question Key`== "MIS4") %>% select(Response) %>% transmute(Response = 6 - Response)

# Add session no. info to the dataframes
n_4kh5$session <- 2
n_5hpk$session <- 3
n_9opr$session <- 2
n_auod$session <- 1
n_daab$session <- 2
n_fhoy$session <- 1
n_hhto$session <- 1
n_k47v$session <- 4
n_l8iw$session <- 4
n_lpz3$session <- 3
n_luva$session <- 3
n_okdo$session <- 1
n_p34a$session <- 1
n_sjbg$session <- 1
n_t7dh$session <- 1
n_txy2$session <- 2
n_ubog$session <- 1
n_vacc$session <- 3
n_wkz6$session <- 4
n_wxzl$session <- 3
n_xdo3$session <- 2
n_xuky$session <- 4
n_zd7j$session <- 2
n_zm3i$session <- 4

# Calculate mean scores for variables within individal dataframes (one variable / dataframe)

# create list of variable names to search for
var_names <- c("cog", "att", "pig", "hed", "HPRS", "moral", "diss", "emo", "emo_obj", "behav", "MIS")
```

# Data wrangle 2
```{r}
# Create function to calculate variable scores

fn_var <- function(d, s1) {
 nam <- paste0(s1, get(d)[1,5]) #create dataframe name from input dataframe and variable string
 print(nam)
 #filter and mutate to create new dataframe
 df_temp <<- get(d) %>% group_by(`PID`) %>% filter(str_detect(`Question Key`, s1) == TRUE) %>% mutate("{s1}" := mean(Response)) %>% select(PID, session, {s1}) %>% distinct()
 if (nrow(df_temp) == 0) return(NULL) #if no data then end function
 assign(nam, df_temp, envir = .GlobalEnv) #assign new dataframe to global environment ie. outside of local function
}

for (i in 1:length(var_names)) {
lapply(dflist, fn_var, s1 = var_names[i] )
}

# remove old dataframes
rm(list = dflist)
rm(df_temp)

a <- rbind(att1, att2, att3, att4)

#create list of remaining dataframes
# dflist <- Filter(function(x) is.data.frame(get(x)), ls())
# plyr::join_all(list(dflist), by=c('PID', "session"), type='left')

plyr::join_all(list(mget(dflist)), by=c("PID", "session"), type='left')

plyr::join_all(list(a, behav1), by=c("PID", "session"), type='left')


```

## Assumption checks
```{r}

# Reliability - Cronbach alpha

df %>% group_by(`Participant Private ID`) %>% filter(str_detect(`Question Key`, "diss") == TRUE) %>% mutate(alpha = psych::alpha(Response))

# Normality (Shapiro/QQ)





# Unifactorial scales - HPRS/MIS

# 


```

setwd("C:/Users/Ben 10/Documents/Paul COG NEURO MSc/Empirical project/MAIN study dummy data") 

#create list of dataframes
dflist <- Filter(function(x) is.data.frame(get(x)), ls())

# Generic tidy up - remove beginning/end and quantised data lines, select only relevant columns
for (i in 1:length(dflist)) {
df_temp <- get(dflist[i]) %>% filter(`Question Key` != "END QUESTIONNAIRE" &  `Question Key` != "BEGIN QUESTIONNAIRE", !grepl("quantised", get(dflist[i])$`Question Key`)  ) %>% select(`Participant Private ID`, `Question Key`, Response) 
rm()
# Add new data frame from this file to overall data frame
  if (i == 1) {df <- df_temp} else {df <- rbind(df, df_temp)}


